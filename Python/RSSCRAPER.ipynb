{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedParser():\n",
    "    def CNN_parser():\n",
    "        CNN_URLS = {\n",
    "        \"Top Stories\": \"http://rss.cnn.com/rss/edition.rss\",\n",
    "        \"World\": \"http://rss.cnn.com/rss/edition_world.rss\",\n",
    "        \"Africa\": \"http://rss.cnn.com/rss/edition_africa.rss\",\n",
    "        \"Americas\": \"http://rss.cnn.com/rss/edition_americas.rss\",\n",
    "        \"Asia\": \"http://rss.cnn.com/rss/edition_asia.rss\",\n",
    "        \"Europe\": \"http://rss.cnn.com/rss/edition_europe.rss\",\n",
    "        \"Middle East\": \"http://rss.cnn.com/rss/edition_meast.rss\",\n",
    "        \"U.S.\": \"http://rss.cnn.com/rss/edition_us.rss\",\n",
    "        \"Money\": \"http://rss.cnn.com/rss/money_news_international.rss\",\n",
    "        \"Technology\": \"http://rss.cnn.com/rss/edition_technology.rss\",\n",
    "        \"Science & Space\": \"http://rss.cnn.com/rss/edition_space.rss\",\n",
    "        \"Entertainment\":\"http://rss.cnn.com/rss/edition_entertainment.rss\",\n",
    "        \"World Sport\":\"http://rss.cnn.com/rss/edition_sport.rss\",\n",
    "        \"Football\" : \"http://rss.cnn.com/rss/edition_football.rss\",\n",
    "        \"Golf\": \"http://rss.cnn.com/rss/edition_golf.rss\",\n",
    "        \"Motorsport\": \"http://rss.cnn.com/rss/edition_motorsport.rss\",\n",
    "        \"Tennis\": \"http://rss.cnn.com/rss/edition_tennis.rss\",\n",
    "        \"Travel\":\"http://rss.cnn.com/rss/edition_travel.rss\",\n",
    "        \"Video\":\"http://rss.cnn.com/rss/cnn_freevideo.rss\",\n",
    "        \"Most Recent\":\"http://rss.cnn.com/rss/cnn_latest.rss\"}\n",
    "\n",
    "        def getSubtitle(i):\n",
    "            try: \n",
    "                return CNN_RSS.entries[i].summary_detail.value\n",
    "            except:\n",
    "                return \"N/A\"\n",
    "        def getPublished(i):\n",
    "            try: \n",
    "                return CNN_RSS.entries[i].published\n",
    "            except:\n",
    "                return \"N/A\"\n",
    "        def getMedia(i):\n",
    "            try: \n",
    "                return CNN_RSS.entries[i].media_content[0]['url']\n",
    "            except:\n",
    "                return \"N/A\"\n",
    "\n",
    "        CNN_feed = []\n",
    "        for k in range(len(CNN_URLS)):\n",
    "            CNN_RSS = feedparser.parse(list(CNN_URLS.values())[k])\n",
    "            for i in range(len(CNN_RSS.entries)):\n",
    "                title = [CNN_RSS.entries[i].title for i in range(len(CNN_RSS.entries))]\n",
    "                subtitle = [ getSubtitle(i) for i in range(len(CNN_RSS.entries))]\n",
    "                url = [CNN_RSS.entries[i].links[0].href for i in range(len(CNN_RSS.entries))]\n",
    "                timestamp = [getPublished(i) for i in range(len(CNN_RSS.entries))]\n",
    "                original_image = [getMedia(i) for i in range(len(CNN_RSS.entries))]\n",
    "                section = [list(CNN_URLS.keys())[k] for i in range(len(CNN_RSS.entries))]\n",
    "                CNN_feed.append([title, subtitle, url, timestamp, original_image])\n",
    "\n",
    "        return CNN_feed\n",
    "\n",
    "    def NYT_parser():\n",
    "        NYT_URLS = {\n",
    "        \"World\":\"https://rss.nytimes.com/services/xml/rss/nyt/World.xml\",\n",
    "        \"Africa\":\"https://rss.nytimes.com/services/xml/rss/nyt/Africa.xml\",\n",
    "        \"Americas\":\"https://rss.nytimes.com/services/xml/rss/nyt/Americas.xml\"\n",
    "        \"Asia Pacific\":\"https://rss.nytimes.com/services/xml/rss/nyt/AsiaPacific.xml\",\n",
    "        \"Europe\":\"https://rss.nytimes.com/services/xml/rss/nyt/Europe.xml\",\n",
    "        \"Middle East\":\"https://rss.nytimes.com/services/xml/rss/nyt/MiddleEast.xml\",\n",
    "        \"US\":\"https://rss.nytimes.com/services/xml/rss/nyt/US.xml\",\n",
    "        \"Education\":\"https://rss.nytimes.com/services/xml/rss/nyt/Education.xml\",\n",
    "        \"Politics\":\"https://rss.nytimes.com/services/xml/rss/nyt/Politics.xml\",\n",
    "        \"Business\":\"https://rss.nytimes.com/services/xml/rss/nyt/Business.xml\",\n",
    "        \"Technology\":\"https://rss.nytimes.com/services/xml/rss/nyt/Technology.xml\",\n",
    "        \"Sports\":\"https://rss.nytimes.com/services/xml/rss/nyt/Sports.xml\",\n",
    "        \"Science\":\"https://rss.nytimes.com/services/xml/rss/nyt/Science.xml\",\n",
    "        \"Environment\":\"https://rss.nytimes.com/services/xml/rss/nyt/Climate.xml\",\n",
    "        \"Health\":\"https://www.nytimes.com/services/xml/rss/nyt/Health.xml\",\n",
    "        \"Art\":\"https://rss.nytimes.com/services/xml/rss/nyt/Arts.xml\"\n",
    "    }\n",
    "        NYT_feed = []\n",
    "        def getNYTMedia(i):\n",
    "            try: \n",
    "                return media = NYT_RSS.entries[i].media_content[0]['url']\n",
    "            except:\n",
    "                return \"N/A\"\n",
    "\n",
    "        for k in range(len(NYT_URLS)):\n",
    "            NYT_RSS = feedparser.parse(list(NYT_URLS.values())[k]).entries\n",
    "            for i in range(len(NYT_RSS)):\n",
    "                title = [NYT_RSS.entries[i].title for i in range(len(NYT_RSS))]\n",
    "                url = [NYT_RSS.entries[i].link for i in range(len(NYT_RSS))]\n",
    "                summary = [NYT_RSS.entries[i].summary for i in range(len(NYT_RSS))]\n",
    "                timestamp = [NYT_RSS.entries[i].published for i in range(len(NYT_RSS))]\n",
    "                media = [getNYTMedia(i) for i in range(len(NYT_RSS))]\n",
    "                section = [list(NYT_URLS.keys())[k] for i in range(len(NYT_RSS))]\n",
    "                NYT_feed.append([title, summary, url, timestamp, media, section])\n",
    "\n",
    "        return NYT_feed\n",
    "\n",
    "    def FOX_parser():\n",
    "            FOX_RSS = {\n",
    "        \"Latest\": \"http://feeds.foxnews.com/foxnews/latest\",\n",
    "        \"National\" : \"http://feeds.foxnews.com/foxnews/national\",\n",
    "        \"World\" : \"http://feeds.foxnews.com/foxnews/world\",\n",
    "        \"Politics\" : \"http://feeds.foxnews.com/foxnews/politics\",\n",
    "        \"Business\" : \"http://feeds.foxnews.com/foxnews/business\",\n",
    "        \"SciTech\" : \"http://feeds.foxnews.com/foxnews/scitech\",\n",
    "        \"Health\" : \"http://feeds.foxnews.com/foxnews/health\",\n",
    "        \"Entertainment\" : \"http://feeds.foxnews.com/foxnews/entertainment\",\n",
    "        \"Views\" : \"http://feeds.foxnews.com/foxnews/views\"\n",
    "            }\n",
    "        def getFoxMedia(i):\n",
    "            try:\n",
    "                return FOX_RSS.entries[0].media_content[0]['url']\n",
    "            except:\n",
    "                return \"N/A\"\n",
    "\n",
    "        FOX_feed = []\n",
    "            for k in range(len(USAT_URLS)):\n",
    "                FOX_RSS = feedparser.parse(list(USAT_URLS.values())[k])\n",
    "                for i in range(len(USAT_RSS)):\n",
    "                    title = [FOX_RSS.entries[0].title for i in range(len(FOX_RSS))]\n",
    "                    summary = [FOX_RSS.entries[0].summary for i in range(len(FOX_RSS))]\n",
    "                    url = [FOX_RSS.entries[i].link for i in range(len(FOX_RSS))]\n",
    "                    timestamp = [FOX_RSS.entries[0].published for i in range(len(FOX_RSS))]\n",
    "                    image = [getFoxMedia(i) for i in range(len(FOX_RSS))]\n",
    "                    section = [list(USAT_URLS.keys())[k] for i in range(len(USAT_RSS))]\n",
    "                    FOX_feed.append([title, summary, url, timestamp, image, section])\n",
    "        return FOX_feed\n",
    "\n",
    "    def WSJ_parser():\n",
    "        #Proxys?? Da error 503, hay que ver como hacerle\n",
    "        WSJ_URLS = {\n",
    "        \"World\": \"https://feeds.a.dj.com/rss/RSSWorldNews.xml\",\n",
    "        \"Opinion\": \"https://feeds.a.dj.com/rss/RSSOpinion.xml\",\n",
    "        \"Business\":\"https://feeds.a.dj.com/rss/WSJcomUSBusiness.xml\",\n",
    "        \"Markets\":\"https://feeds.a.dj.com/rss/RSSMarketsMain.xml\",\n",
    "        \"Technology\":\"https://feeds.a.dj.com/rss/RSSWSJD.xml\",\n",
    "        \"Lifestyle\":\"https://feeds.a.dj.com/rss/RSSLifestyle.xml\"}\n",
    "\n",
    "    def BBC_parser():\n",
    "        BBC_URLS = {\n",
    "        \"World\":\"http://feeds.bbci.co.uk/news/world/rss.xml\",\n",
    "        \"UK\":\"http://feeds.bbci.co.uk/news/uk/rss.xml\",\n",
    "        \"Business\":\"http://feeds.bbci.co.uk/news/business/rss.xml\",\n",
    "        \"Politics\": \"http://feeds.bbci.co.uk/news/politics/rss.xml\",\n",
    "        \"Health\": \"http://feeds.bbci.co.uk/news/health/rss.xml\",\n",
    "        \"Education\": \"http://feeds.bbci.co.uk/news/education/rss.xml\",\n",
    "        \"Science\": \"http://feeds.bbci.co.uk/news/science_and_environment/rss.xml\",\n",
    "        \"Technology\": \"http://feeds.bbci.co.uk/news/technology/rss.xml\",\n",
    "        \"Entretainment & Arts\": \"http://feeds.bbci.co.uk/news/entertainment_and_arts/rss.xml\"}\n",
    "\n",
    "        BBC_feed = pd.DataFrame()\n",
    "        for k in range(len(BBC_URLS)):\n",
    "            BBC_RSS = feedparser.parse(list(BBC_URLS.values())[k])\n",
    "            for i in range(len(BBC_RSS.entries)):\n",
    "                title = [BBC_RSS.entries[i].title for i in range(len(BBC_RSS.entries))]\n",
    "                subtitle = [ BBC_RSS.entries[i].summary for i in range(len(BBC_RSS.entries))]\n",
    "                url = [BBC_RSS.entries[i].links[0].href for i in range(len(BBC_RSS.entries))]\n",
    "                timestamp = [BBC_RSS.entries[0].published for i in range(len(BBC_RSS.entries))]\n",
    "                section = [list(BBC_RSS.keys())[k] for i in range(len(BBC_RSS.entries))]\n",
    "                BBC_RSS_feed_p = pd.DataFrame([title, subtitle, url, timestamp, section]).transpose()\n",
    "                BBC_feed.append(CNN_RSS_feed_p, ignore_index=True)\n",
    "\n",
    "        return BBC_feed\n",
    "\n",
    "    def USAT_parser():\n",
    "\n",
    "        USAT_URLS = {\n",
    "        \"US\":\"http://rssfeeds.usatoday.com/UsatodaycomNation-TopStories\",\n",
    "        \"World\":\"http://rssfeeds.usatoday.com/UsatodaycomWorld-TopStories\",\n",
    "        \"Opinion\":\"http://rssfeeds.usatoday.com/News-Opinion\",\n",
    "        \"Sports\":\"http://rssfeeds.usatoday.com/UsatodaycomSports-TopStories\",\n",
    "        \"Lifestyle\":\"http://rssfeeds.usatoday.com/usatoday-LifeTopStories\",\n",
    "        \"Money\":\"http://rssfeeds.usatoday.com/UsatodaycomMoney-TopStories\",\n",
    "        \"Tech\":\"http://rssfeeds.usatoday.com/usatoday-TechTopStories\",\n",
    "        \"Travel\":\"http://rssfeeds.usatoday.com/UsatodaycomTravel-TopStories\"}\n",
    "\n",
    "        def getUSATMedia(i):\n",
    "            try: \n",
    "                return USAT_feed_p.entries[i].links[1].href\n",
    "            except:\n",
    "                return \"N/A\"\n",
    "        USAT_feed = []\n",
    "        for k in range(len(USAT_URLS)):\n",
    "            USAT_RSS = feedparser.parse(list(USAT_URLS.values())[k])\n",
    "            for i in range(len(USAT_RSS)):\n",
    "                title =  [USAT_feed_p.entries[i].title for i in range(len(USAT_RSS))]\n",
    "                summary = [re.findall('(?<=<p>).*(?=</p>)', USAT_feed_p.entries[i].content[0].value)[0]) for i in range(len(USAT_RSS))]\n",
    "                url = [USAT_feed_p.entries[i].feedburner_origlink for i in range(len(USAT_RSS))]\n",
    "                timestamp = [USAT_feed_p.entries[i].published for i in range(len(USAT_RSS))]\n",
    "                image = [getUSATMedia(i) for i in range(len(USAT_RSS))]\n",
    "                section = [list(USAT_URLS.keys())[k] for i in range(len(USAT_RSS))]\n",
    "                USAT_feed.append([title, summary, url, timestamp, image, section])\n",
    "\n",
    "        return USAT_feed\n",
    "    \n",
    "    def main(self):\n",
    "        resultMatrix = [CNN_parser(), USAT_parser(), BBC_parser(), FOX_parser(), NYT_parser()]\n",
    "        return pd.DataFrame(resultMatrix).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOX_RSS = feedparser.parse(\"http://feeds.foxnews.com/foxnews/latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://static.foxnews.com/foxnews.com/content/uploads/2019/12/iStock-181879495.jpg'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOX_RSS.entries[0].media_content[0]['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewFeed = FeedParser()\n",
    "feeds = FeedParser.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
